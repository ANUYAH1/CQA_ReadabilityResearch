{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result was published in the paper: Can Readability Enhance Recommendations on Community Question Answering Sites?\n",
    "In proceedings of the 11th ACM Conference on Recommender Systems, August 2017 \n",
    "Authors: Oghenemaro Anuyah, Ion Madrazo Azpiazu, David McNeill, Sole Pera \n",
    "\n",
    "We used the Yahoo! L16 webscope dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import operator\n",
    "import collections\n",
    "import random                                                                                                                                   \n",
    "import os    \n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import nltk.data                                                                                                                                \n",
    "import string    \n",
    "import collections\n",
    "import collections as c                                                                                                            \n",
    "import tflearn                                                                                  \n",
    "import tensorflow as tf from scipy.io.arff import loadarff           \n",
    "import json                                                                                                                                      \n",
    "import scipy as sp                                                                                                                              \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "from scipy.spatial import distance\n",
    "from sklearn import linear_model\n",
    "from __future__ import division, print_function, absolute_import  \n",
    "from tflearn.data_utils import to_categorical, pad_sequences, VocabularyProcessor \n",
    "from sklearn import datasets, svm, metrics                                                                                                      \n",
    "from sklearn.naive_bayes import MultinomialNB                                                                                                   \n",
    "from sklearn.ensemble import RandomForestClassifier                                                                                             \n",
    "from sklearn.neighbors import KNeighborsClassifier                                                                                              \n",
    "from sklearn.neural_network import MLPClassifier                                                                                               \n",
    "from sklearn.tree import DecisionTreeClassifier       \n",
    "from tflearn.datasets import imdb    \n",
    "from scipy.stats import pearsonr                                                                                                                                 \n",
    "from sys import argvfrom tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.contrib import learnimport string\n",
    "from textstat.textstat import textstat\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from functools import reduce  \n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('data/L16/ydata-yanswers-question-answer-ratings-v1_0.txt',names=['query_id','queries','question_id','query_ques_match','query_ans_sat','question_subject','question_content','answer','question_category_id','question_category_name'], delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[['query_id','queries','question_subject','question_content','answer','query_ans_sat']] #select only the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>queries</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question_content</th>\n",
       "      <th>answer</th>\n",
       "      <th>query_ans_sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "      <td>18 kids counting religion</td>\n",
       "      <td>what religion is the duggar family?  18 kids a...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>Evangelical or Baptist I believe.</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910</td>\n",
       "      <td>1949 slang</td>\n",
       "      <td>1949 to 1950 often used slang words?</td>\n",
       "      <td>I would like to know some basic slang words fr...</td>\n",
       "      <td>Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                    queries  \\\n",
       "0       341  18 kids counting religion   \n",
       "1       910                 1949 slang   \n",
       "\n",
       "                                    question_subject  \\\n",
       "0  what religion is the duggar family?  18 kids a...   \n",
       "1               1949 to 1950 often used slang words?   \n",
       "\n",
       "                                    question_content  \\\n",
       "0                                                 \\t   \n",
       "1  I would like to know some basic slang words fr...   \n",
       "\n",
       "                                              answer  query_ans_sat  \n",
       "0                  Evangelical or Baptist I believe.       1.666667  \n",
       "1  Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) ##check the length of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for the Content Similarity \n",
    "\n",
    "- This code is based on a paper by li et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHA = 0.2\n",
    "BETA = 0.45\n",
    "ETA = 0.4\n",
    "PHI = 0.2\n",
    "DELTA = 0.85\n",
    "\n",
    "brown_freqs = dict()\n",
    "N = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_synset_pair(word_1, word_2):\n",
    "    \"\"\" \n",
    "    Choose the pair with highest path similarity among all pairs. \n",
    "    Mimics pattern-seeking behavior of humans.\n",
    "    \"\"\"\n",
    "    max_sim = -1.0\n",
    "    synsets_1 = wn.synsets(word_1)\n",
    "    synsets_2 = wn.synsets(word_2)\n",
    "    if len(synsets_1) == 0 or len(synsets_2) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        max_sim = -1.0\n",
    "        best_pair = None, None\n",
    "        for synset_1 in synsets_1:\n",
    "            for synset_2 in synsets_2:\n",
    "                sim = wn.path_similarity(synset_1, synset_2)\n",
    "                if sim == None:\n",
    "                    sim = 0\n",
    "                if sim > max_sim:\n",
    "                    max_sim = sim\n",
    "                    best_pair = synset_1, synset_2\n",
    "        return best_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length_dist(synset_1, synset_2):\n",
    "    \"\"\"\n",
    "    Return a measure of the length of the shortest path in the semantic \n",
    "    ontology (Wordnet in our case as well as the paper's) between two \n",
    "    synsets.\n",
    "    \"\"\"\n",
    "    l_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None: \n",
    "        return 0.0\n",
    "    if synset_1 == synset_2:\n",
    "        # if synset_1 and synset_2 are the same synset return 0\n",
    "        l_dist = 0.0\n",
    "    else:\n",
    "        wset_1 = set([str(x.name()) for x in synset_1.lemmas()])        \n",
    "        wset_2 = set([str(x.name()) for x in synset_2.lemmas()])\n",
    "        if len(wset_1.intersection(wset_2)) > 0:\n",
    "            # if synset_1 != synset_2 but there is word overlap, return 1.0\n",
    "            l_dist = 1.0\n",
    "        else:\n",
    "            # just compute the shortest path between the two\n",
    "            l_dist = synset_1.shortest_path_distance(synset_2)\n",
    "            if l_dist is None:\n",
    "                l_dist = 0.0\n",
    "    # normalize path length to the range [0,1]\n",
    "    return math.exp(-ALPHA * l_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hierarchy_dist(synset_1, synset_2):\n",
    "    \"\"\"\n",
    "    Return a measure of depth in the ontology to model the fact that \n",
    "    nodes closer to the root are broader and have less semantic similarity\n",
    "    than nodes further away from the root.\n",
    "    \"\"\"\n",
    "    h_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None: \n",
    "        return h_dist\n",
    "    if synset_1 == synset_2:\n",
    "        # return the depth of one of synset_1 or synset_2\n",
    "        h_dist = max([x[1] for x in synset_1.hypernym_distances()])\n",
    "    else:\n",
    "        # find the max depth of least common subsumer\n",
    "        hypernyms_1 = {x[0]:x[1] for x in synset_1.hypernym_distances()}\n",
    "        hypernyms_2 = {x[0]:x[1] for x in synset_2.hypernym_distances()}\n",
    "        lcs_candidates = set(hypernyms_1.keys()).intersection(\n",
    "            set(hypernyms_2.keys()))\n",
    "        if len(lcs_candidates) > 0:\n",
    "            lcs_dists = []\n",
    "            for lcs_candidate in lcs_candidates:\n",
    "                lcs_d1 = 0\n",
    "                if lcs_candidate in hypernyms_1:\n",
    "                    lcs_d1 = hypernyms_1[lcs_candidate]\n",
    "                lcs_d2 = 0\n",
    "                if lcs_candidate in hypernyms_2:\n",
    "                    lcs_d2 = hypernyms_2[lcs_candidate]\n",
    "                lcs_dists.append(max([lcs_d1, lcs_d2]))\n",
    "            h_dist = max(lcs_dists)\n",
    "        else:\n",
    "            h_dist = 0\n",
    "    return ((math.exp(BETA * h_dist) - math.exp(-BETA * h_dist)) / \n",
    "        (math.exp(BETA * h_dist) + math.exp(-BETA * h_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_similarity(word_1, word_2):\n",
    "    synset_pair = get_best_synset_pair(word_1, word_2)\n",
    "    return (length_dist(synset_pair[0], synset_pair[1]) * \n",
    "        hierarchy_dist(synset_pair[0], synset_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_word(word, word_set):\n",
    "    \"\"\"\n",
    "    Find the word in the joint word set that is most similar to the word\n",
    "    passed in. We use the algorithm above to compute word similarity between\n",
    "    the word and each word in the joint word set, and return the most similar\n",
    "    word and the actual similarity value.\n",
    "    \"\"\"\n",
    "    max_sim = -1.0\n",
    "    sim_word = \"\"\n",
    "    for ref_word in word_set:\n",
    "        sim = word_similarity(word, ref_word)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            sim_word = ref_word\n",
    "    return sim_word, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_content(lookup_word):\n",
    "    \"\"\"\n",
    "    Uses the Brown corpus available in NLTK to calculate a Laplace\n",
    "    smoothed frequency distribution of words, then uses this information\n",
    "    to compute the information content of the lookup_word.\n",
    "    \"\"\"\n",
    "    global N\n",
    "    if N == 0:\n",
    "        # poor man's lazy evaluation\n",
    "        for sent in brown.sents():\n",
    "            for word in sent:\n",
    "                word = word.lower()\n",
    "                if word not in brown_freqs:\n",
    "                    brown_freqs[word] = 0\n",
    "                brown_freqs[word] = brown_freqs[word] + 1\n",
    "                N = N + 1\n",
    "    lookup_word = lookup_word.lower()\n",
    "    n = 0 if lookup_word not in brown_freqs else brown_freqs[lookup_word]\n",
    "    return 1.0 - (math.log(n + 1) / math.log(N + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def semantic_vector(words, joint_words, info_content_norm):\n",
    "    \"\"\"\n",
    "    Computes the semantic vector of a sentence. The sentence is passed in as\n",
    "    a collection of words. The size of the semantic vector is the same as the\n",
    "    size of the joint word set. The elements are 1 if a word in the sentence\n",
    "    already exists in the joint word set, or the similarity of the word to the\n",
    "    most similar word in the joint word set if it doesn't. Both values are \n",
    "    further normalized by the word's (and similar word's) information content\n",
    "    if info_content_norm is True.\n",
    "    \"\"\"\n",
    "    sent_set = set(words)\n",
    "    semvec = np.zeros(len(joint_words))\n",
    "    i = 0\n",
    "    for joint_word in joint_words:\n",
    "        if joint_word in sent_set:\n",
    "            # if word in union exists in the sentence, s(i) = 1 (unnormalized)\n",
    "            semvec[i] = 1.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * math.pow(info_content(joint_word), 2)\n",
    "        else:\n",
    "            # find the most similar word in the joint set and set the sim value\n",
    "            sim_word, max_sim = most_similar_word(joint_word, sent_set)\n",
    "            semvec[i] = PHI if max_sim > PHI else 0.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * info_content(joint_word) * info_content(sim_word)\n",
    "        i = i + 1\n",
    "    return semvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def semantic_similarity(sentence_1, sentence_2, info_content_norm):\n",
    "    \"\"\"\n",
    "    Computes the semantic similarity between two sentences as the cosine\n",
    "    similarity between the semantic vectors computed for each sentence.\n",
    "    \"\"\"\n",
    "    words_1 = nltk.word_tokenize(sentence_1)\n",
    "    words_2 = nltk.word_tokenize(sentence_2)\n",
    "    joint_words = set(words_1).union(set(words_2))\n",
    "    vec_1 = semantic_vector(words_1, joint_words, info_content_norm)\n",
    "    vec_2 = semantic_vector(words_2, joint_words, info_content_norm)\n",
    "    return np.dot(vec_1, vec_2.T) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_order_vector(words, joint_words, windex):\n",
    "    \"\"\"\n",
    "    Computes the word order vector for a sentence. The sentence is passed\n",
    "    in as a collection of words. The size of the word order vector is the\n",
    "    same as the size of the joint word set. The elements of the word order\n",
    "    vector are the position mapping (from the windex dictionary) of the \n",
    "    word in the joint set if the word exists in the sentence. If the word\n",
    "    does not exist in the sentence, then the value of the element is the \n",
    "    position of the most similar word in the sentence as long as the similarity\n",
    "    is above the threshold ETA.\n",
    "    \"\"\"\n",
    "    wovec = np.zeros(len(joint_words))\n",
    "    i = 0\n",
    "    wordset = set(words)\n",
    "    for joint_word in joint_words:\n",
    "        if joint_word in wordset:\n",
    "            # word in joint_words found in sentence, just populate the index\n",
    "            wovec[i] = windex[joint_word]\n",
    "        else:\n",
    "            # word not in joint_words, find most similar word and populate\n",
    "            # word_vector with the thresholded similarity\n",
    "            sim_word, max_sim = most_similar_word(joint_word, wordset)\n",
    "            if max_sim > ETA:\n",
    "                wovec[i] = windex[sim_word]\n",
    "            else:\n",
    "                wovec[i] = 0\n",
    "        i = i + 1\n",
    "    return wovec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_order_similarity(sentence_1, sentence_2):\n",
    "    \"\"\"\n",
    "    Computes the word-order similarity between two sentences as the normalized\n",
    "    difference of word order between the two sentences.\n",
    "    \"\"\"\n",
    "    words_1 = nltk.word_tokenize(sentence_1)\n",
    "    words_2 = nltk.word_tokenize(sentence_2)\n",
    "    joint_words = list(set(words_1).union(set(words_2)))\n",
    "    windex = {x[1]: x[0] for x in enumerate(joint_words)}\n",
    "    r1 = word_order_vector(words_1, joint_words, windex)\n",
    "    r2 = word_order_vector(words_2, joint_words, windex)\n",
    "    return 1.0 - (np.linalg.norm(r1 - r2) / np.linalg.norm(r1 + r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(sentence_1, sentence_2, info_content_norm):\n",
    "    \"\"\"\n",
    "    Calculate the semantic similarity between two sentences. The last \n",
    "    parameter is True or False depending on whether information content\n",
    "    normalization is desired or not.\n",
    "    \"\"\"\n",
    "    return DELTA * semantic_similarity(sentence_1, sentence_2, info_content_norm) + \\\n",
    "        (1.0 - DELTA) * word_order_similarity(sentence_1, sentence_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using Read2vec readability\n",
    "\n",
    "- Removed code (Yet to be released by author. Send email to git owner for access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#requires an array of words\n",
    "#not symbols, just numebrs and letters\n",
    "#max sentence lenght == 20, words after the 20th word will be ignored\n",
    "#readability is normalzied between 0 and 1. 0 means harder 1 simpler\n",
    "def getReadabilityForSentence(words = []):\n",
    "    wordIds = list(vocabProcessor.transform([\" \".join(words)]))\n",
    "    return sess.run(ypred, feed_dict={x: wordIds, keep_prob:1.0})[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91219229"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getReadabilityForSentence(words = [\"the\",\"door\",\"is\",\"closed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79620558"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getReadabilityForSentence(words=[\"accomodate\",\"the\",\"beautification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99997926"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getReadabilityForSentence(words=\"she is a beautiful girl\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91219229"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getReadabilityForSentence(words=[\"the\",\"door\",\"is\",\"closed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031201795"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getReadabilityForSentence(words=\"the presidential parliament has just concluded the elections however the president himself will not condone injustice\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Read2vec_sentences(sent=[]):   \n",
    "    scores=[]\n",
    "    sentences=[]\n",
    "    lid=[]\n",
    "    split_sentences=(tokenizer.tokenize(str(sent).replace(\"\\\\n\",\" \")))\n",
    "    sentences= [s.lower().split() for s in split_sentences]          \n",
    "    for s in sentences:\n",
    "        scores.append(getReadabilityForSentence(words=s))\n",
    "    n_s=sorted(scores, reverse=False)   \n",
    "    return np.median(n_s) #use the median of the readability scores to calculate the overall readability of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950276"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Read2vec_sentences('The honorable president has arrived. He just spoke about how appreciative he is about effort to eradicate poverty.  she is good. she is fine. she is a girl. she is. commotion accomodability beauticonability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data['query_answer_sim']=[semantic_similarity(x, y,True) for x, y in zip(data.queries, data.answer)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data=data.rename(columns={\"ques_ans_sim\":\"query_answer_sim\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_words=pd.read_csv('data/simple_words.txt', names=['words'], delimiter=('\\n \\t'), engine='python') #for dale-challe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_words=[s for s in simple_words.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2950"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simple_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Flesch Readability Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def syllables(word):\n",
    "    count = 0\n",
    "    vowels = 'aeiou'    \n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if word.endswith('le'):\n",
    "            count+=1\n",
    "        if word.endswith('ie'):\n",
    "            count+=1\n",
    "        if count == 0:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Flesch_readability(text=[]):    \n",
    "    split_sentences= tokenizer.tokenize(str(text).replace(\"\\\\n\",\" \"))\n",
    "    tokens=[x.split() for x in split_sentences]\n",
    "    for w in tokens:\n",
    "        cleaned_words = [[''.join(c for c in s if c not in string.punctuation) for s in m] for m in tokens]\n",
    "        cleaned_words = [[s.lower() for s in k if s] for k in cleaned_words]\n",
    "        cleaned_words=[[w for w in k if w.isalpha()] for k in cleaned_words]\n",
    "    words=[a for m in cleaned_words for a in m ]    \n",
    "    try:\n",
    "        Total_words=len(words)\n",
    "        Total_sentences=len(cleaned_words)    \n",
    "        Total_Syllable=0\n",
    "        for w in words:\n",
    "            Total_Syllable+=syllables(w)\n",
    "        A=(Total_words)/(Total_sentences)\n",
    "        B=(Total_Syllable)/(Total_words)\n",
    "    except Exception:\n",
    "        A= 1\n",
    "        B= 1\n",
    "        pass\n",
    "    else:\n",
    "        pass    \n",
    "    flesch_kincaid_difficulty=(206.835-(1.015*A)-(84.6*B))\n",
    "    flesch_kincaid_grade_level=(0.39*A)+(11.8*B)-15.59\n",
    "    if flesch_kincaid_difficulty>100:\n",
    "        flesch_kincaid_difficulty=100\n",
    "    if flesch_kincaid_difficulty<0:\n",
    "        flesch_kincaid_difficulty=1\n",
    "    return flesch_kincaid_difficulty  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.66583333333335"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flesch_readability(\"Proposed a method that could produce a more distinct and content based relevance assessment. The methods are Reconciled Relevance ranking and reconciled relevance. In all, this paper is about ranking the documents retrieved in response to children's queries. It is important that we re-rank the documents (part of the filtering), after filtering the documents.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.37\n"
     ]
    }
   ],
   "source": [
    "print (textstat.flesch_reading_ease('a sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['flesch_query']= [textstat.flesch_reading_ease(x) for x in (data.queries)]\n",
    "data['flesch_answer']= [textstat.flesch_reading_ease(x) for x in (data.answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scorex1=[x for x in data.flesch_query]\n",
    "\n",
    "new_s1=[]\n",
    "for s in scorex1:\n",
    "    if s<0:\n",
    "        sc1=0\n",
    "    elif s>100:\n",
    "        sc1=100\n",
    "    else:\n",
    "        sc1=s\n",
    "    new_s1.append(sc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorex=[x for x in data.flesch_answer]\n",
    "\n",
    "new_s2=[]\n",
    "for s in scorex:\n",
    "    if s<0:\n",
    "        sc=0\n",
    "    elif s>100:\n",
    "        sc=100\n",
    "    else:\n",
    "        sc=s\n",
    "    new_s2.append(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['flesch_answer']= new_s2\n",
    "data['flesch_query']= new_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scorex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>queries</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question_content</th>\n",
       "      <th>answer</th>\n",
       "      <th>query_ans_sat</th>\n",
       "      <th>flesch_query</th>\n",
       "      <th>flesch_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "      <td>18 kids counting religion</td>\n",
       "      <td>what religion is the duggar family?  18 kids a...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>Evangelical or Baptist I believe.</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>84.34</td>\n",
       "      <td>32.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910</td>\n",
       "      <td>1949 slang</td>\n",
       "      <td>1949 to 1950 often used slang words?</td>\n",
       "      <td>I would like to know some basic slang words fr...</td>\n",
       "      <td>Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607</td>\n",
       "      <td>1950 pfennig</td>\n",
       "      <td>How much is this German 10 Pfennig Swastika co...</td>\n",
       "      <td>So, I was looking through my foreign coins... ...</td>\n",
       "      <td>The 10 Reich-pfennig is made of zinc so that i...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>100.00</td>\n",
       "      <td>89.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>It means the amount of empty space (how much l...</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>How many grams are in 2 liters (of water)?</td>\n",
       "      <td>?\\t</td>\n",
       "      <td>1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>Toyota Camry Stationwagon: engine CC and does ...</td>\n",
       "      <td>I know nothing about car engines, and I need t...</td>\n",
       "      <td>Only Mazda offered rotary engines, Toyota did ...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>100.00</td>\n",
       "      <td>71.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>I need help on my h.w. in math. its a 6th grad...</td>\n",
       "      <td>A tank that is 25 cm long, 10 cm wide, and 8 c...</td>\n",
       "      <td>Firstly, calculate the capacity of the tank in...</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>525</td>\n",
       "      <td>7 point gpa scale</td>\n",
       "      <td>how to convert gpa to 4.0 scale?&gt;?</td>\n",
       "      <td>im having a problem converting my gpa from the...</td>\n",
       "      <td>Your guidence counselor has a sheet to give yo...</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>100.00</td>\n",
       "      <td>77.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>525</td>\n",
       "      <td>7 point gpa scale</td>\n",
       "      <td>On a 7 point scale, my GPA is 6.4. What is it ...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>aroun 3.8, but ill calculate the exact for you...</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>525</td>\n",
       "      <td>7 point gpa scale</td>\n",
       "      <td>How do you calculate gpa on a 7 point scale (a...</td>\n",
       "      <td>\\tok well thats the way my school does it\\tk (...</td>\n",
       "      <td>This doesn't make any sense.\\t\\tthere's only 5...</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                     queries  \\\n",
       "0       341   18 kids counting religion   \n",
       "1       910                  1949 slang   \n",
       "2       607                1950 pfennig   \n",
       "3       593  2000 cc is how many liters   \n",
       "4       593  2000 cc is how many liters   \n",
       "5       593  2000 cc is how many liters   \n",
       "6       593  2000 cc is how many liters   \n",
       "7       525           7 point gpa scale   \n",
       "8       525           7 point gpa scale   \n",
       "9       525           7 point gpa scale   \n",
       "\n",
       "                                    question_subject  \\\n",
       "0  what religion is the duggar family?  18 kids a...   \n",
       "1               1949 to 1950 often used slang words?   \n",
       "2  How much is this German 10 Pfennig Swastika co...   \n",
       "3  whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...   \n",
       "4         How many grams are in 2 liters (of water)?   \n",
       "5  Toyota Camry Stationwagon: engine CC and does ...   \n",
       "6  I need help on my h.w. in math. its a 6th grad...   \n",
       "7                 how to convert gpa to 4.0 scale?>?   \n",
       "8  On a 7 point scale, my GPA is 6.4. What is it ...   \n",
       "9  How do you calculate gpa on a 7 point scale (a...   \n",
       "\n",
       "                                    question_content  \\\n",
       "0                                                 \\t   \n",
       "1  I would like to know some basic slang words fr...   \n",
       "2  So, I was looking through my foreign coins... ...   \n",
       "3                                                 \\t   \n",
       "4                                                ?\\t   \n",
       "5  I know nothing about car engines, and I need t...   \n",
       "6  A tank that is 25 cm long, 10 cm wide, and 8 c...   \n",
       "7  im having a problem converting my gpa from the...   \n",
       "8                                                 \\t   \n",
       "9  \\tok well thats the way my school does it\\tk (...   \n",
       "\n",
       "                                              answer  query_ans_sat  \\\n",
       "0                  Evangelical or Baptist I believe.       1.666667   \n",
       "1  Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...       1.000000   \n",
       "2  The 10 Reich-pfennig is made of zinc so that i...       1.428571   \n",
       "3  It means the amount of empty space (how much l...       2.571429   \n",
       "4  1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...       1.428571   \n",
       "5  Only Mazda offered rotary engines, Toyota did ...       2.857143   \n",
       "6  Firstly, calculate the capacity of the tank in...       1.285714   \n",
       "7  Your guidence counselor has a sheet to give yo...       1.714286   \n",
       "8  aroun 3.8, but ill calculate the exact for you...       1.571429   \n",
       "9  This doesn't make any sense.\\t\\tthere's only 5...       2.571429   \n",
       "\n",
       "   flesch_query  flesch_answer  \n",
       "0         84.34          32.56  \n",
       "1        100.00          96.18  \n",
       "2        100.00          89.99  \n",
       "3        100.00          83.66  \n",
       "4        100.00         100.00  \n",
       "5        100.00          71.31  \n",
       "6        100.00         100.00  \n",
       "7        100.00          77.94  \n",
       "8        100.00         100.00  \n",
       "9        100.00         100.00  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Read2vec_query']= [Read2vec_sentences(x) for x in (data.queries)]\n",
    "data['Read2vec_answer']= [Read2vec_sentences(x) for x in (data.answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del data['read2vec_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['flesch_dist']=[distance.euclidean(x,y) for x,y in zip (data.flesch_query, data.flesch_answer)]\n",
    "data['read2vec_dist']=[distance.euclidean(x,y) for x,y in zip (data.Read2vec_query, data.Read2vec_answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data.rename(columns={'q_a_flesch_dist': 'flesch_dist', 'q_a_read2vec_dist': 'read2vec_dist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Relevance_score'] = data.query_ans_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values= [x for x in data.Relevance_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_v=[]\n",
    "for x in values:\n",
    "    if x >=1 and x < 1.5:\n",
    "        v=3\n",
    "    elif x >= 1.5 and x < 2.5:\n",
    "        v=2\n",
    "    else:\n",
    "        v=1\n",
    "    new_v.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.Relevance_score=new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>queries</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question_content</th>\n",
       "      <th>answer</th>\n",
       "      <th>query_ans_sat</th>\n",
       "      <th>flesch_query</th>\n",
       "      <th>flesch_answer</th>\n",
       "      <th>Read2vec_query</th>\n",
       "      <th>Read2vec_answer</th>\n",
       "      <th>flesch_dist</th>\n",
       "      <th>read2vec_dist</th>\n",
       "      <th>Relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "      <td>18 kids counting religion</td>\n",
       "      <td>what religion is the duggar family?  18 kids a...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>Evangelical or Baptist I believe.</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>84.34</td>\n",
       "      <td>32.56</td>\n",
       "      <td>0.200418</td>\n",
       "      <td>0.929365</td>\n",
       "      <td>51.78</td>\n",
       "      <td>0.728947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910</td>\n",
       "      <td>1949 slang</td>\n",
       "      <td>1949 to 1950 often used slang words?</td>\n",
       "      <td>I would like to know some basic slang words fr...</td>\n",
       "      <td>Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.18</td>\n",
       "      <td>0.764292</td>\n",
       "      <td>0.555969</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.208323</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607</td>\n",
       "      <td>1950 pfennig</td>\n",
       "      <td>How much is this German 10 Pfennig Swastika co...</td>\n",
       "      <td>So, I was looking through my foreign coins... ...</td>\n",
       "      <td>The 10 Reich-pfennig is made of zinc so that i...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>100.00</td>\n",
       "      <td>89.99</td>\n",
       "      <td>0.805796</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>10.01</td>\n",
       "      <td>0.194203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>It means the amount of empty space (how much l...</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.66</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.088361</td>\n",
       "      <td>16.34</td>\n",
       "      <td>0.329628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>How many grams are in 2 liters (of water)?</td>\n",
       "      <td>?\\t</td>\n",
       "      <td>1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.582009</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                     queries  \\\n",
       "0       341   18 kids counting religion   \n",
       "1       910                  1949 slang   \n",
       "2       607                1950 pfennig   \n",
       "3       593  2000 cc is how many liters   \n",
       "4       593  2000 cc is how many liters   \n",
       "\n",
       "                                    question_subject  \\\n",
       "0  what religion is the duggar family?  18 kids a...   \n",
       "1               1949 to 1950 often used slang words?   \n",
       "2  How much is this German 10 Pfennig Swastika co...   \n",
       "3  whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...   \n",
       "4         How many grams are in 2 liters (of water)?   \n",
       "\n",
       "                                    question_content  \\\n",
       "0                                                 \\t   \n",
       "1  I would like to know some basic slang words fr...   \n",
       "2  So, I was looking through my foreign coins... ...   \n",
       "3                                                 \\t   \n",
       "4                                                ?\\t   \n",
       "\n",
       "                                              answer  query_ans_sat  \\\n",
       "0                  Evangelical or Baptist I believe.       1.666667   \n",
       "1  Keen\\tHep\\tSpiffy\\tGam \\tGat\\tCat's pajamas\\tC...       1.000000   \n",
       "2  The 10 Reich-pfennig is made of zinc so that i...       1.428571   \n",
       "3  It means the amount of empty space (how much l...       2.571429   \n",
       "4  1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...       1.428571   \n",
       "\n",
       "   flesch_query  flesch_answer  Read2vec_query  Read2vec_answer  flesch_dist  \\\n",
       "0         84.34          32.56        0.200418         0.929365        51.78   \n",
       "1        100.00          96.18        0.764292         0.555969         3.82   \n",
       "2        100.00          89.99        0.805796         0.999999        10.01   \n",
       "3        100.00          83.66        0.417989         0.088361        16.34   \n",
       "4        100.00         100.00        0.417989         0.999997         0.00   \n",
       "\n",
       "   read2vec_dist  Relevance_score  \n",
       "0       0.728947                2  \n",
       "1       0.208323                3  \n",
       "2       0.194203                3  \n",
       "3       0.329628                1  \n",
       "4       0.582009                3  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ids=[k for k in data.query_id] #get all query ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cnt= Counter(all_ids)\n",
    "new_ids= [k for k,v in cnt.items() if v>1] #saves query ids that have more than one answer to the question\n",
    "other_ids= [k for k,v in cnt.items() if v==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data= data[data.query_id.isin(other_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_data['query_answer_sim']=[semantic_similarity(x, y,True) for x, y in zip(train_data.queries, train_data.answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_data['query_question_sim']=[semantic_similarity(x, y,True) for x, y in zip(train_data.queries, train_data.question_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data= data[data.query_id.isin(new_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_data['query_question_sim']=[semantic_similarity(x, y,True) for x, y in zip(new_data.queries, new_data.question_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['query_answer_sim']=[semantic_similarity(x, y,True) for x, y in zip(test_data.queries, test_data.answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_data['query_question_sim']=[semantic_similarity(x, y,True) for x, y in zip(test_data.queries, test_data.question_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>queries</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question_content</th>\n",
       "      <th>answer</th>\n",
       "      <th>query_ans_sat</th>\n",
       "      <th>flesch_query</th>\n",
       "      <th>flesch_answer</th>\n",
       "      <th>Read2vec_query</th>\n",
       "      <th>Read2vec_answer</th>\n",
       "      <th>flesch_dist</th>\n",
       "      <th>read2vec_dist</th>\n",
       "      <th>Relevance_score</th>\n",
       "      <th>query_answer_sim</th>\n",
       "      <th>query_question_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>It means the amount of empty space (how much l...</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.66</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.088361</td>\n",
       "      <td>16.34</td>\n",
       "      <td>0.329628</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131272</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>How many grams are in 2 liters (of water)?</td>\n",
       "      <td>?\\t</td>\n",
       "      <td>1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.582009</td>\n",
       "      <td>3</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>593</td>\n",
       "      <td>2000 cc is how many liters</td>\n",
       "      <td>Toyota Camry Stationwagon: engine CC and does ...</td>\n",
       "      <td>I know nothing about car engines, and I need t...</td>\n",
       "      <td>Only Mazda offered rotary engines, Toyota did ...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.31</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.517005</td>\n",
       "      <td>28.69</td>\n",
       "      <td>0.099016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030845</td>\n",
       "      <td>0.198355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                     queries  \\\n",
       "3       593  2000 cc is how many liters   \n",
       "4       593  2000 cc is how many liters   \n",
       "5       593  2000 cc is how many liters   \n",
       "\n",
       "                                    question_subject  \\\n",
       "3  whAT DOES IT MEAN MOTOR CAPCITY 2000 CC OR 150...   \n",
       "4         How many grams are in 2 liters (of water)?   \n",
       "5  Toyota Camry Stationwagon: engine CC and does ...   \n",
       "\n",
       "                                    question_content  \\\n",
       "3                                                 \\t   \n",
       "4                                                ?\\t   \n",
       "5  I know nothing about car engines, and I need t...   \n",
       "\n",
       "                                              answer  query_ans_sat  \\\n",
       "3  It means the amount of empty space (how much l...       2.571429   \n",
       "4  1 cc of water = 1 gram\\t\\t2 liters = 2000 cc =...       1.428571   \n",
       "5  Only Mazda offered rotary engines, Toyota did ...       2.857143   \n",
       "\n",
       "   flesch_query  flesch_answer  Read2vec_query  Read2vec_answer  flesch_dist  \\\n",
       "3         100.0          83.66        0.417989         0.088361        16.34   \n",
       "4         100.0         100.00        0.417989         0.999997         0.00   \n",
       "5         100.0          71.31        0.417989         0.517005        28.69   \n",
       "\n",
       "   read2vec_dist  Relevance_score  query_answer_sim  query_question_sim  \n",
       "3       0.329628                1          0.131272            0.000000  \n",
       "4       0.582009                3          0.735512            0.000000  \n",
       "5       0.099016                1          0.030845            0.198355  "
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=train_data.replace([np.nan, -np.inf, np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_data.Relevance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_rec(q_id=''):    \n",
    "    query_id=int(q_id)   \n",
    "    recs=list(set([s for s in test_data['answer'][test_data.query_id==query_id]]))\n",
    "    random.shuffle(recs)\n",
    "    return recs      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity_rec(q_id=''):    \n",
    "    query_id=int(q_id)    \n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('query_question_sim', ascending=False)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Firstly, calculate the capacity of the tank in cubic cm.\\t\\t25 x 10 x 8 = 2,000 cubic cm\\t\\tThen convert cubic cm (or \"cc\") to liters: 1,000 cc = 1 litre\\t\\tTherefore the tank holds 2 liters of water.\\t\\t',\n",
       " 'Only Mazda offered rotary engines, Toyota did not. Mazda still has the RX-8 with a rotary engine.',\n",
       " 'It means the amount of empty space (how much liquid it would hold) in a motorcycle engine when the piston is at the bottom of the stroke.  For instance a chevy 350 Cubic  Inch motor holds 350 cubic inches of liquid.  To compare - a 1600cc holds approx. 95 Cubic Inches of liquid.',\n",
       " '1 cc of water = 1 gram\\t\\t2 liters = 2000 cc = 2000 grams = 2 Kg']"
      ]
     },
     "execution_count": 1453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_rec('593')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Flesch_rec(q_id=''):    \n",
    "    query_id=int(q_id)\n",
    "    #readability= Flesch_readability\n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('flesch_answer', ascending=False)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return(sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read2vec_rec(q_id=''):    \n",
    "    query_id=int(q_id)\n",
    "    #readability= Read2vec_readability\n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('Read2vec_answer', ascending=False)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read2vec_rec_inv(q_id=''):    \n",
    "    query_id=int(q_id)\n",
    "    #readability= Inverse of Read2vec_readability\n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('Read2vec_answer', ascending=True)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It means the amount of empty space (how much liquid it would hold) in a motorcycle engine when the piston is at the bottom of the stroke.  For instance a chevy 350 Cubic  Inch motor holds 350 cubic inches of liquid.  To compare - a 1600cc holds approx. 95 Cubic Inches of liquid.',\n",
       " 'Only Mazda offered rotary engines, Toyota did not. Mazda still has the RX-8 with a rotary engine.',\n",
       " 'Firstly, calculate the capacity of the tank in cubic cm.\\t\\t25 x 10 x 8 = 2,000 cubic cm\\t\\tThen convert cubic cm (or \"cc\") to liters: 1,000 cc = 1 litre\\t\\tTherefore the tank holds 2 liters of water.\\t\\t',\n",
       " '1 cc of water = 1 gram\\t\\t2 liters = 2000 cc = 2000 grams = 2 Kg']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Read2vec_rec_inv('593')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Flesch_q_a_distance(q_id=''):\n",
    "    sem_sim=[]\n",
    "    values={}\n",
    "    query_id=int(q_id)\n",
    "    #readability= Flesch_readability\n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('flesch_dist', ascending=True)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Read2vec_q_a_distance(q_id=''):    \n",
    "    query_id=int(q_id)\n",
    "    #readability= Flesch_readability\n",
    "    own= test_data[test_data['query_id']==query_id]\n",
    "    own_rank= own.sort_values('read2vec_dist', ascending=True)\n",
    "    sem=[s for s in own_rank.answer]\n",
    "    return sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only Mazda offered rotary engines, Toyota did not. Mazda still has the RX-8 with a rotary engine.',\n",
       " 'Firstly, calculate the capacity of the tank in cubic cm.\\t\\t25 x 10 x 8 = 2,000 cubic cm\\t\\tThen convert cubic cm (or \"cc\") to liters: 1,000 cc = 1 litre\\t\\tTherefore the tank holds 2 liters of water.\\t\\t',\n",
       " 'It means the amount of empty space (how much liquid it would hold) in a motorcycle engine when the piston is at the bottom of the stroke.  For instance a chevy 350 Cubic  Inch motor holds 350 cubic inches of liquid.  To compare - a 1600cc holds approx. 95 Cubic Inches of liquid.',\n",
       " '1 cc of water = 1 gram\\t\\t2 liters = 2000 cc = 2000 grams = 2 Kg']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Read2vec_q_a_distance('593')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_ranks(q_id='', func=''):\n",
    "    que_id=int(q_id)\n",
    "    Recs=func(que_id)\n",
    "    own= test_data[test_data['query_id']==que_id]\n",
    "    ideal= own.sort_values('query_ans_sat', ascending=True)\n",
    "    ideal=ideal['answer'][:1]\n",
    "    ideal=' '.join(s for s in ideal)\n",
    "    \n",
    "    position= Recs.index(ideal)+1\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_ranks('593', func=random_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines_mrr=pd.DataFrame(columns=('query_id','random_mrr','similarity_mrr','flesch_mrr','Read2vec_mrr','flesch_dist_mrr','Read2vec_dist_mrr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baselines_mrr.query_id=new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines_mrr.random_mrr=[1/(Get_ranks(x, func=random_rec)) for x in baselines_mrr.query_id]\n",
    "baselines_mrr.similarity_mrr=[1/Get_ranks(x, func=similarity_rec) for x in baselines_mrr.query_id]\n",
    "baselines_mrr.flesch_mrr=[1/Get_ranks(x, func=Flesch_rec) for x in baselines_mrr.query_id]\n",
    "baselines_mrr.Read2vec_mrr=[1/Get_ranks(x, func=Read2vec_rec) for x in baselines_mrr.query_id]\n",
    "baselines_mrr.flesch_dist_mrr=[1/Get_ranks(x, func=Flesch_q_a_distance) for x in baselines_mrr.query_id]\n",
    "baselines_mrr.Read2vec_dist_mrr=[1/Get_ranks(x, func=Read2vec_q_a_distance) for x in baselines_mrr.query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines_mrr['Read2vec_inv']=[1/(Get_ranks(x, func=Read2vec_rec_inv)) for x in baselines_mrr.query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>random_mrr</th>\n",
       "      <th>similarity_mrr</th>\n",
       "      <th>flesch_mrr</th>\n",
       "      <th>Read2vec_mrr</th>\n",
       "      <th>flesch_dist_mrr</th>\n",
       "      <th>Read2vec_dist_mrr</th>\n",
       "      <th>Read2vec_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  random_mrr  similarity_mrr  flesch_mrr  Read2vec_mrr  \\\n",
       "0         1    0.166667        0.166667    1.000000           0.1   \n",
       "1         2    0.500000        0.333333    0.166667           1.0   \n",
       "\n",
       "   flesch_dist_mrr  Read2vec_dist_mrr  Read2vec_inv  \n",
       "0            0.125           0.200000      0.500000  \n",
       "1            0.250           0.111111      0.111111  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines_mrr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines_mrr=baselines_mrr.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_ranks_mrr = pd.DataFrame(columns=('random','similarity','flesch','Read2vec','Read2vec_inv', 'flesch_dist','Read2vec_dist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_ranks_mrr['random']= [baselines_mrr['random_mrr'].mean()]\n",
    "average_ranks_mrr['similarity']= [baselines_mrr['similarity_mrr'].mean()]\n",
    "average_ranks_mrr['flesch']= [baselines_mrr['flesch_mrr'].mean()]\n",
    "average_ranks_mrr['Read2vec']= [baselines_mrr['Read2vec_mrr'].mean()]\n",
    "average_ranks_mrr['Read2vec_inv']= [baselines_mrr['Read2vec_inv'].mean()]\n",
    "average_ranks_mrr['flesch_dist']= [baselines_mrr['flesch_dist_mrr'].mean()]\n",
    "average_ranks_mrr['Read2vec_dist']= [baselines_mrr['Read2vec_dist_mrr'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "      <th>similarity</th>\n",
       "      <th>flesch</th>\n",
       "      <th>Read2vec</th>\n",
       "      <th>Read2vec_inv</th>\n",
       "      <th>flesch_dist</th>\n",
       "      <th>Read2vec_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486112</td>\n",
       "      <td>0.548105</td>\n",
       "      <td>0.444367</td>\n",
       "      <td>0.470044</td>\n",
       "      <td>0.463713</td>\n",
       "      <td>0.509728</td>\n",
       "      <td>0.464754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     random  similarity    flesch  Read2vec  Read2vec_inv  flesch_dist  \\\n",
       "0  0.486112    0.548105  0.444367  0.470044      0.463713     0.509728   \n",
       "\n",
       "   Read2vec_dist  \n",
       "0       0.464754  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_ranks_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq= list(set([v for k,v in cnt.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "numbers=0\n",
    "new_dict={}\n",
    "\n",
    "for k,v in cnt.items():\n",
    "    if v==11:        \n",
    "        numbers=numbers+1\n",
    "        new_dict[1]=numbers\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 17}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_questions(nums=''):\n",
    "    counts=0\n",
    "    numbs=0\n",
    "    numbers_dict={}    \n",
    "    \n",
    "    for k,v in cnt.items():\n",
    "        if v==nums:\n",
    "            numbs=numbs+1                       \n",
    "            counts=counts+1\n",
    "    numbers_dict[str(numbs)+' querie(s)']= str(nums)+' answer(s)'        \n",
    "    return numbers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers_list=[]\n",
    "for f in freq:\n",
    "    numbers_list.append(count_questions(f).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'245 querie(s)': '1 answer(s)'},\n",
       " {'61 querie(s)': '2 answer(s)'},\n",
       " {'13 querie(s)': '3 answer(s)'},\n",
       " {'5 querie(s)': '4 answer(s)'},\n",
       " {'4 querie(s)': '5 answer(s)'},\n",
       " {'7 querie(s)': '6 answer(s)'},\n",
       " {'10 querie(s)': '7 answer(s)'},\n",
       " {'10 querie(s)': '8 answer(s)'},\n",
       " {'18 querie(s)': '9 answer(s)'},\n",
       " {'16 querie(s)': '10 answer(s)'},\n",
       " {'17 querie(s)': '11 answer(s)'},\n",
       " {'11 querie(s)': '12 answer(s)'},\n",
       " {'11 querie(s)': '13 answer(s)'},\n",
       " {'7 querie(s)': '14 answer(s)'},\n",
       " {'1 querie(s)': '16 answer(s)'},\n",
       " {'1 querie(s)': '17 answer(s)'},\n",
       " {'1 querie(s)': '18 answer(s)'}]"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Use different classifiers for the error rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logiregr = linear_model.LogisticRegression(C=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with flesch answer (Model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_x= train_data[['query_answer_sim','flesch_answer']]\n",
    "mod1_y= train_data[['Relevance_score']]\n",
    "\n",
    "logiregr.fit(mod1_x,mod1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "mod1=test_data[['query_answer_sim','flesch_answer', 'Relevance_score']]\n",
    "\n",
    "mod1_test=mod1[['query_answer_sim','flesch_answer']]\n",
    "\n",
    "mod1_res=logiregr.predict(mod1_test)\n",
    "\n",
    "mod1['pred']=mod1_res\n",
    "mod1['error_rate']=[(x-y) for x,y in zip(mod1.pred,mod1.Relevance_score)]\n",
    "\n",
    "mod1_error=[mod1['error_rate'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5852187028657617]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with flesch distance (Model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7111613876319759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr2 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod2_x= train_data[['query_answer_sim','flesch_dist']] #train with similarty and flesch distance\n",
    "mod2_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr2.fit(mod2_x,mod2_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod2=test_data[['query_answer_sim','flesch_dist', 'Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod2_test=mod2[['query_answer_sim','flesch_dist']] #select the data for prediction\n",
    "\n",
    "mod2_res=logiregr2.predict(mod2_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod2['pred']=mod2_res #put the scores in the dataframe\n",
    "mod2['error_rate']=[(x-y) for x,y in zip(mod2.pred,mod2.Relevance_score)] #calculate the error\n",
    "\n",
    "mod2_error=[mod2['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod2_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with read2vec answer (Model 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6093514328808446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr3 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod3_x= train_data[['query_answer_sim','Read2vec_answer']] #train with similarty and flesch distance\n",
    "mod3_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr3.fit(mod3_x,mod3_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod3=test_data[['query_answer_sim','Read2vec_answer', 'Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod3_test=mod3[['query_answer_sim','Read2vec_answer']] #select the data for prediction\n",
    "\n",
    "mod3_res=logiregr3.predict(mod3_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod3['pred']=mod3_res #put the scores in the dataframe\n",
    "mod3['error_rate']=[(x-y) for x,y in zip(mod3.pred,mod3.Relevance_score)] #calculate the error\n",
    "\n",
    "mod3_error=[mod3['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod3_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with read2vec distance (Model 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6327300150829562]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr4 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod4_x= train_data[['query_answer_sim','read2vec_dist']] #train with similarty and flesch distance\n",
    "mod4_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr4.fit(mod4_x,mod4_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod4=test_data[['query_answer_sim','read2vec_dist', 'Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod4_test=mod4[['query_answer_sim','read2vec_dist']] #select the data for prediction\n",
    "\n",
    "mod4_res=logiregr4.predict(mod4_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod4['pred']=mod4_res #put the scores in the dataframe\n",
    "mod4['error_rate']=[(x-y) for x,y in zip(mod4.pred,mod4.Relevance_score)] #calculate the error\n",
    "\n",
    "mod4_error=[mod4['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod4_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with flesch answer and flesch distance (Model 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5844645550527904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr5 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod5_x= train_data[['query_answer_sim','flesch_answer','flesch_dist']] #train with similarty and flesch distance\n",
    "mod5_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr5.fit(mod5_x,mod5_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod5=test_data[['query_answer_sim','flesch_answer','flesch_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod5_test=mod5[['query_answer_sim','flesch_answer','flesch_dist']] #select the data for prediction\n",
    "\n",
    "mod5_res=logiregr5.predict(mod5_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod5['pred']=mod5_res #put the scores in the dataframe\n",
    "mod5['error_rate']=[(x-y) for x,y in zip(mod5.pred,mod5.Relevance_score)] #calculate the error\n",
    "\n",
    "mod5_error=[mod5['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod5_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with read2vec answer and read2vec distance (Model 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5746606334841629]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr6 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod6_x= train_data[['query_answer_sim','Read2vec_answer','read2vec_dist']] #train with similarty and flesch distance\n",
    "mod6_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr6.fit(mod6_x,mod6_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod6=test_data[['query_answer_sim','Read2vec_answer','read2vec_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod6_test=mod6[['query_answer_sim','Read2vec_answer','read2vec_dist']] #select the data for prediction\n",
    "\n",
    "mod6_res=logiregr6.predict(mod6_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod6['pred']=mod6_res #put the scores in the dataframe\n",
    "mod6['error_rate']=[(x-y) for x,y in zip(mod6.pred,mod6.Relevance_score)] #calculate the error\n",
    "\n",
    "mod6_error=[mod6['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod6_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with flesch answer and read2vec distance (Model 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5414781297134238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr7 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod7_x= train_data[['query_answer_sim','flesch_answer','read2vec_dist']] #train with similarty and flesch distance\n",
    "mod7_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr7.fit(mod7_x,mod7_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod7=test_data[['query_answer_sim','flesch_answer','read2vec_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod7_test=mod7[['query_answer_sim','flesch_answer','read2vec_dist']] #select the data for prediction\n",
    "\n",
    "mod7_res=logiregr7.predict(mod7_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod7['pred']=mod7_res #put the scores in the dataframe\n",
    "mod7['error_rate']=[(x-y) for x,y in zip(mod7.pred,mod7.Relevance_score)] #calculate the error\n",
    "\n",
    "mod7_error=[mod7['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod7_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with read2vec answer and flesch distance (Model 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6131221719457014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr8 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod8_x= train_data[['query_answer_sim','Read2vec_answer','flesch_dist']] #train with similarty and flesch distance\n",
    "mod8_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr8.fit(mod8_x,mod8_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod8=test_data[['query_answer_sim','Read2vec_answer','flesch_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod8_test=mod8[['query_answer_sim','Read2vec_answer','flesch_dist']] #select the data for prediction\n",
    "\n",
    "mod8_res=logiregr8.predict(mod8_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod8['pred']=mod8_res #put the scores in the dataframe\n",
    "mod8['error_rate']=[(x-y) for x,y in zip(mod8.pred,mod8.Relevance_score)] #calculate the error\n",
    "\n",
    "mod8_error=[mod8['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod8_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with flesch ans, read2vec answer and read2vec distance (Model 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.526395173453997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr9 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod9_x= train_data[['query_answer_sim','flesch_answer','Read2vec_answer','read2vec_dist']] #train with similarty and flesch distance\n",
    "mod9_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr9.fit(mod9_x,mod9_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod9=test_data[['query_answer_sim','flesch_answer','Read2vec_answer','read2vec_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod9_test=mod9[['query_answer_sim','flesch_answer','Read2vec_answer','read2vec_dist']] #select the data for prediction\n",
    "\n",
    "mod9_res=logiregr9.predict(mod9_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod9['pred']=mod9_res #put the scores in the dataframe\n",
    "mod9['error_rate']=[(x-y) for x,y in zip(mod9.pred,mod9.Relevance_score)] #calculate the error\n",
    "\n",
    "mod9_error=[mod9['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod9_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Using the combination of the similarity with read2vec ans, flesch answer and flesch distance (Model 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5535444947209653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr10 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod10_x= train_data[['query_answer_sim','flesch_answer','Read2vec_answer','flesch_dist']] #train with similarty and flesch distance\n",
    "mod10_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr10.fit(mod10_x,mod10_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod10=test_data[['query_answer_sim','flesch_answer','Read2vec_answer','flesch_dist','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod10_test=mod10[['query_answer_sim','flesch_answer','Read2vec_answer','flesch_dist']] #select the data for prediction\n",
    "\n",
    "mod10_res=logiregr10.predict(mod10_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod10['pred']=mod10_res #put the scores in the dataframe\n",
    "mod10['error_rate']=[(x-y) for x,y in zip(mod10.pred,mod10.Relevance_score)] #calculate the error\n",
    "\n",
    "mod10_error=[mod10['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod10_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6244343891402715]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "logiregr11 = linear_model.LogisticRegression(C=1.0)\n",
    "\n",
    "mod11_x= train_data[['query_answer_sim','query_question_sim','read2vec_dist']] #train with similarty and flesch distance\n",
    "mod11_y= train_data[['Relevance_score']] #fit it with the relevance score\n",
    "\n",
    "logiregr11.fit(mod11_x,mod11_y) #fit imto the model\n",
    "\n",
    "\n",
    "mod11=test_data[['query_answer_sim','flesch_answer','Read2vec_answer','flesch_dist','read2vec_dist','query_question_sim','Relevance_score']] #select some columns from the test set\n",
    "\n",
    "mod11_test=mod11[['query_answer_sim','query_question_sim','read2vec_dist']] #select the data for prediction\n",
    "\n",
    "mod11_res=logiregr11.predict(mod11_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod11['pred']=mod11_res #put the scores in the dataframe\n",
    "mod11['error_rate']=[(x-y) for x,y in zip(mod11.pred,mod11.Relevance_score)] #calculate the error\n",
    "\n",
    "mod11_error=[mod11['error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod11_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.26636207])"
      ]
     },
     "execution_count": 1498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm11.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58113814,  0.20465715,  0.11752131]])"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm11.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model 7 returned the lowest error, as a result of the combination, so we will use this instead for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(q_id=''):  \n",
    "   \n",
    "    query_id=int(q_id)   \n",
    "    \n",
    "    own=test_data[test_data['query_id']==query_id]\n",
    "    own=own[['query_id','queries','question_content','query_question_sim','answer','query_answer_sim','Read2vec_answer','flesch_answer','read2vec_dist','Relevance_score']]\n",
    "    own_tx=own[['query_answer_sim','query_question_sim','read2vec_dist']]   \n",
    "    own_res=lm11.predict(own_tx) #predict the relevance scores for the second model\n",
    "    own['pred']=own_res #put the scores in the dataframe  \n",
    "    own.pred=[int(round(d)) for d in own.pred]\n",
    "\n",
    "    ideal= own.sort_values('Relevance_score', ascending=False) #sorts the dataframe using the satisfaction\n",
    "    ideal=ideal['answer'][:1] #the one with the lowest sat_score is the most relevant, select the first answer\n",
    "    ideal=' '.join(str(s) for s in ideal) #convert answer to string\n",
    "    own_rank= own.sort_values('pred', ascending=False) #firstly rank the selected dataframe by the similarity\n",
    "    \n",
    "    Recs=[s for s in own_rank.answer] #The recommendations are the answers based on the rank\n",
    "    \n",
    "    position= Recs.index(ideal)+1 #check where the relevant answer was ranked among the list of recommendations\n",
    "    #own_rank['MRR']=1/position\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(q_id=593)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### MRR base on our new approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "New_Mrr=pd.DataFrame(columns=('query_id','Combination'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "New_Mrr.query_id=new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "New_Mrr.Combination=[1/pipeline(s) for s in New_Mrr.query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Get_ranks('593', func=random_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "New_Mrr['Query_Ques_sim']=[1/Get_ranks(s, func=similarity_rec) for s in New_Mrr.query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Average_new_mrr= [New_Mrr['Query_Ques_sim'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4488318819925036]"
      ]
     },
     "execution_count": 1494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_new_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Average_Mrr=pd.DataFrame(columns=('Combination','Random','Flesch_Answer','Read2Vec_distance','Similarity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Average_Mrr.Similarity= [New_Mrr['Similarity'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>Combination</th>\n",
       "      <th>Read2Vec_dist</th>\n",
       "      <th>Random</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Flesch_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  Combination  Read2Vec_dist    Random  Similarity  Flesch_Answer\n",
       "0         1        0.125       0.200000  0.500000    0.166667       1.000000\n",
       "1         2        0.500       0.111111  0.250000    0.333333       0.166667\n",
       "2         3        0.500       0.166667  0.142857    1.000000       0.500000\n",
       "3         4        0.250       0.500000  0.250000    0.166667       1.000000\n",
       "4         5        1.000       0.250000  0.100000    0.166667       0.111111"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Mrr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Random</th>\n",
       "      <th>Flesch_Answer</th>\n",
       "      <th>Read2Vec_distance</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707772</td>\n",
       "      <td>0.439479</td>\n",
       "      <td>0.444367</td>\n",
       "      <td>0.464754</td>\n",
       "      <td>0.548105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Combination    Random  Flesch_Answer  Read2Vec_distance  Similarity\n",
       "0     0.707772  0.439479       0.444367           0.464754    0.548105"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_Mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/Mrr.csv','w') as f:\n",
    "    print (New_Mrr.to_csv(sep=',', index=False, header=True), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pipeline('593',func='flesch_answer',a=0.3,b=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining content similarity with flesch answer/flesch distance pair or read2vec answer/read2vec distance pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipelines2(q_id='',func1='', func2='', a='',b='',c=''):\n",
    "    a=float(a) #datapoint a\n",
    "    b=float(b) #datapoint b\n",
    "    c=float(c)\n",
    "    x=func1 #I can call any function based on the readability e.g Flesch\n",
    "    y=func2 #for the distance\n",
    "    #sim(qanda) and readabilityofa and distance\n",
    "    query_id=int(q_id) #The query id is recognized as a string, so i convert to an integer\n",
    "    own=new_data[new_data['query_id']==query_id] #select only rows that corresponds to the query_id entered   \n",
    "    own=own[['query_id','queries','question_content','answer','query_ans_sat','query_answer_sim',x,y]] #select relevant columns\n",
    "    ideal= own.sort_values('query_ans_sat', ascending=True) #sorts the dataframe using the satisfaction\n",
    "    ideal=ideal['answer'][:1] #the one with the lowest sat_score is the most relevant, select the first answer\n",
    "    ideal=' '.join(str(s) for s in ideal) #convert answer to string\n",
    "    own_rank= own.sort_values('query_answer_sim', ascending=False) #firstly rank the selected dataframe by the similarity\n",
    "    if x=='flesch_answer' or y=='flesch_answer':        \n",
    "        own_rank['query_answer_sim']=[100* x for x in own_rank.query_answer_sim] #normalize the similarity with the readability\n",
    "    elif x=='q_a_flesch_dist' or y=='q_a_flesch_dist':\n",
    "        own_rank['query_answer_sim']=[100* x for x in own_rank.query_answer_sim]\n",
    "    else:\n",
    "        own_rank['query_answer_sim']=[x for x in own_rank.query_answer_sim] #normalize the similarity with the readability\n",
    "    own_rank['data_point']=[(a*d)+(b*e)+(c*f) for d,e,f in zip(own_rank.query_answer_sim, own_rank[x], own_rank[y])] #check for the best datapoint\n",
    "    own_rank= own_rank.sort_values('data_point', ascending=False) #rank based on the highest datapoint value\n",
    "    Recs=[s for s in own_rank.answer] #The recommendations are the answers based on the rank\n",
    "    \n",
    "    position= Recs.index(ideal)+1    #check where the relevant answer was ranked among the list of recommendations\n",
    "    return 1/position #return the rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39819004524886875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm1 = LinearRegression()\n",
    "\n",
    "lm1.fit(mod1_x,mod1_y) #fit imto the model\n",
    "\n",
    "mod1_lm_res=lm1.predict(mod1_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod1['lm_pred']= mod1_lm_res#put the scores in the dataframe\n",
    "mod1.lm_pred=[int(round(d)) for d in mod1.lm_pred]\n",
    "mod1['lm_error_rate']=[(x-y) for x,y in zip(mod1.lm_pred,mod1.Relevance_score)] #calculate the error\n",
    "\n",
    "mod1_lm_error=[mod1['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod1_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.76695311]\n",
      "[[ 0.65762819 -0.00427898 -0.11772302 -0.00138803]]\n"
     ]
    }
   ],
   "source": [
    "print(lm10.intercept_)\n",
    "print(lm10.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4276018099547511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm2 = LinearRegression()\n",
    "\n",
    "lm2.fit(mod2_x,mod2_y) #fit imto the model\n",
    "\n",
    "mod2_lm_res=lm2.predict(mod2_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod2['lm_pred']=mod2_lm_res #put the scores in the dataframe\n",
    "mod2.lm_pred=[int(round(d)) for d in mod2.lm_pred]\n",
    "mod2['lm_error_rate']=[(x-y) for x,y in zip(mod2.lm_pred,mod2.Relevance_score)] #calculate the error\n",
    "\n",
    "mod2_lm_error=[mod2['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod2_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4079939668174962]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm3 = LinearRegression()\n",
    "\n",
    "lm3.fit(mod3_x,mod3_y) #fit imto the model\n",
    "\n",
    "mod3_lm_res=lm3.predict(mod3_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod3['lm_pred']=mod3_lm_res #put the scores in the dataframe\n",
    "mod3.lm_pred=[int(round(d)) for d in mod3.lm_pred]\n",
    "mod3['lm_error_rate']=[(x-y) for x,y in zip(mod3.lm_pred,mod3.Relevance_score)] #calculate the error\n",
    "\n",
    "mod3_lm_error=[mod3['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod3_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43288084464555054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm4 = LinearRegression()\n",
    "\n",
    "lm4.fit(mod4_x,mod4_y) #fit imto the model\n",
    "\n",
    "mod4_lm_res=lm4.predict(mod4_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod4['lm_pred']=mod4_lm_res #put the scores in the dataframe\n",
    "mod4.lm_pred=[int(round(d)) for d in mod4.lm_pred]\n",
    "mod4['lm_error_rate']=[(x-y) for x,y in zip(mod4.lm_pred,mod4.Relevance_score)] #calculate the error\n",
    "\n",
    "mod4_lm_error=[mod4['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod4_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4034690799396682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm5 = LinearRegression()\n",
    "\n",
    "lm5.fit(mod5_x,mod5_y) #fit imto the model\n",
    "\n",
    "mod5_lm_res=lm5.predict(mod5_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod5['lm_pred']=mod5_lm_res #put the scores in the dataframe\n",
    "mod5.lm_pred=[int(round(d)) for d in mod5.lm_pred]\n",
    "mod5['lm_error_rate']=[(x-y) for x,y in zip(mod5.lm_pred,mod5.Relevance_score)] #calculate the error\n",
    "\n",
    "mod5_lm_error=[mod5['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod5_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4155354449472097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm6 = LinearRegression()\n",
    "\n",
    "lm6.fit(mod6_x,mod6_y) #fit imto the model\n",
    "\n",
    "mod6_lm_res=lm6.predict(mod6_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod6['lm_pred']=mod6_lm_res #put the scores in the dataframe\n",
    "mod6.lm_pred=[int(round(d)) for d in mod6.lm_pred]\n",
    "mod6['lm_error_rate']=[(x-y) for x,y in zip(mod6.lm_pred,mod6.Relevance_score)] #calculate the error\n",
    "\n",
    "mod6_lm_error=[mod6['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod6_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4004524886877828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm7 = LinearRegression()\n",
    "\n",
    "lm7.fit(mod7_x,mod7_y) #fit imto the model\n",
    "\n",
    "mod7_lm_res=lm7.predict(mod7_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod7['lm_pred']=mod7_lm_res #put the scores in the dataframe\n",
    "mod7.lm_pred=[int(round(d)) for d in mod7.lm_pred]\n",
    "\n",
    "mod7['lm_error_rate']=[(x-y) for x,y in zip(mod7.lm_pred,mod7.Relevance_score)] #calculate the error\n",
    "\n",
    "mod7_lm_error=[mod7['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod7_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40497737556561086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm8 = LinearRegression()\n",
    "\n",
    "lm8.fit(mod8_x,mod8_y) #fit imto the model\n",
    "\n",
    "mod8_lm_res=lm8.predict(mod8_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod8['lm_pred']=mod8_lm_res #put the scores in the dataframe\n",
    "mod8.lm_pred=[int(round(d)) for d in mod8.lm_pred]\n",
    "mod8['lm_error_rate']=[(x-y) for x,y in zip(mod8.lm_pred,mod8.Relevance_score)] #calculate the error\n",
    "\n",
    "mod8_lm_error=[mod8['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod8_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39441930618401205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm9 = LinearRegression()\n",
    "\n",
    "lm9.fit(mod9_x,mod9_y) #fit imto the model\n",
    "\n",
    "mod9_lm_res=lm9.predict(mod9_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod9['lm_pred']=mod9_lm_res #put the scores in the dataframe\n",
    "mod9.lm_pred=[int(round(d)) for d in mod9.lm_pred]\n",
    "\n",
    "mod9['lm_error_rate']=[(x-y) for x,y in zip(mod9.lm_pred,mod9.Relevance_score)] #calculate the error\n",
    "\n",
    "mod9_lm_error=[mod9['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod9_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39668174962292607]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm10 = LinearRegression()\n",
    "\n",
    "lm10.fit(mod10_x,mod10_y) #fit imto the model\n",
    "\n",
    "mod10_lm_res=lm10.predict(mod10_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod10['lm_pred']=mod10_lm_res #put the scores in the dataframe\n",
    "mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod10['lm_error_rate']=[(x-y) for x,y in zip(mod10.lm_pred,mod10.Relevance_score)] #calculate the error\n",
    "\n",
    "mod10_lm_error=[mod10['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod10_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42232277526395173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lm11 = LinearRegression()\n",
    "\n",
    "lm11.fit(mod11_x,mod11_y) #fit imto the model\n",
    "\n",
    "mod11_lm_res=lm11.predict(mod11_test) #predict the relevance scores for the second model\n",
    "\n",
    "mod11['lm_pred']=mod11_lm_res #put the scores in the dataframe\n",
    "mod11.lm_pred=[int(round(d)) for d in mod11.lm_pred]\n",
    "mod11['lm_error_rate']=[(x-y) for x,y in zip(mod11.lm_pred,mod11.Relevance_score)] #calculate the error\n",
    "\n",
    "mod11_lm_error=[mod11['lm_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod11_lm_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4381598793363499]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc1.fit(mod10_x,mod10_y) #fit imto the model\n",
    "\n",
    "mod10_rf_res=np.array(rfc1.predict(mod10_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod10['rf_pred']=mod10_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod10['rf_error_rate']=[(x-y) for x,y in zip(mod10.rf_pred,mod10.Relevance_score)] #calculate the error\n",
    "\n",
    "mod10_rf_error=[mod10['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod10_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41855203619909503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc11 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc11.fit(mod1_x,mod1_y) #fit imto the model\n",
    "\n",
    "mod1_rf_res=np.array(rfc11.predict(mod1_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod1['rf_pred']=mod1_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod1['rf_error_rate']=[(x-y) for x,y in zip(mod1.rf_pred,mod1.Relevance_score)] #calculate the error\n",
    "\n",
    "mod1_rf_error=[mod1['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod1_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46907993966817496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc2.fit(mod2_x,mod2_y) #fit imto the model\n",
    "\n",
    "mod2_rf_res=np.array(rfc2.predict(mod2_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod2['rf_pred']=mod2_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod2['rf_error_rate']=[(x-y) for x,y in zip(mod2.rf_pred,mod2.Relevance_score)] #calculate the error\n",
    "\n",
    "mod2_rf_error=[mod2['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod2_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43891402714932126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc3 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc3.fit(mod3_x,mod3_y) #fit imto the model\n",
    "\n",
    "mod3_rf_res=np.array(rfc3.predict(mod3_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod3['rf_pred']=mod3_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod3['rf_error_rate']=[(x-y) for x,y in zip(mod3.rf_pred,mod3.Relevance_score)] #calculate the error\n",
    "\n",
    "mod3_rf_error=[mod3['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod3_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40271493212669685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc4 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc4.fit(mod4_x,mod4_y) #fit imto the model\n",
    "\n",
    "mod4_rf_res=np.array(rfc4.predict(mod4_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod4['rf_pred']=mod4_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod4['rf_error_rate']=[(x-y) for x,y in zip(mod4.rf_pred,mod4.Relevance_score)] #calculate the error\n",
    "\n",
    "mod4_rf_error=[mod4['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod4_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42458521870286575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc5.fit(mod5_x,mod5_y) #fit imto the model\n",
    "\n",
    "mod5_rf_res=np.array(rfc5.predict(mod5_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod5['rf_pred']=mod5_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod5['rf_error_rate']=[(x-y) for x,y in zip(mod5.rf_pred,mod5.Relevance_score)] #calculate the error\n",
    "\n",
    "mod5_rf_error=[mod5['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod5_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41855203619909503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc6 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc6.fit(mod6_x,mod6_y) #fit imto the model\n",
    "\n",
    "mod6_rf_res=np.array(rfc6.predict(mod6_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod6['rf_pred']=mod6_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod6['rf_error_rate']=[(x-y) for x,y in zip(mod6.rf_pred,mod6.Relevance_score)] #calculate the error\n",
    "\n",
    "mod6_rf_error=[mod6['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod6_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45098039215686275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc7 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc7.fit(mod7_x,mod7_y) #fit imto the model\n",
    "\n",
    "mod7_rf_res=np.array(rfc7.predict(mod7_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod7['rf_pred']=mod7_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod7['rf_error_rate']=[(x-y) for x,y in zip(mod7.rf_pred,mod7.Relevance_score)] #calculate the error\n",
    "\n",
    "mod7_rf_error=[mod7['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod7_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4517345399698341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc8 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc8.fit(mod8_x,mod8_y) #fit imto the model\n",
    "\n",
    "mod8_rf_res=np.array(rfc8.predict(mod8_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod8['rf_pred']=mod8_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod8['rf_error_rate']=[(x-y) for x,y in zip(mod8.rf_pred,mod8.Relevance_score)] #calculate the error\n",
    "\n",
    "mod8_rf_error=[mod8['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod8_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4321266968325792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/var/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rfc9 = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "rfc9.fit(mod9_x,mod9_y) #fit imto the model\n",
    "\n",
    "mod9_rf_res=np.array(rfc9.predict(mod9_test))#predict the relevance scores for the second model\n",
    "\n",
    "mod9['rf_pred']=mod9_rf_res #put the scores in the dataframe\n",
    "#mod10.lm_pred=[int(round(d)) for d in mod10.lm_pred]\n",
    "mod9['rf_error_rate']=[(x-y) for x,y in zip(mod9.rf_pred,mod9.Relevance_score)] #calculate the error\n",
    "\n",
    "mod9_rf_error=[mod9['rf_error_rate'].mean()] #get the mean of the error\n",
    "\n",
    "print(mod9_rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NDCG_scores(q_id=''):\n",
    "    que_id=int(q_id)\n",
    "    recs=similarity_rec(que_id)\n",
    "    own= test_data[test_data['query_id']==que_id]    \n",
    "    ideal= own.sort_values('Relevance_score', ascending=False)\n",
    "    ideal_list=[s for s in ideal.Relevance_score] #ideal rank of the items. this list is sorted\n",
    "    ideal_answers=[s for s in ideal.answer] #these are the list of answers when the dataframe is sorted by relevance\n",
    "    #unsorted_list =[s for s in own.Relevance_score] #where it initially ranked the items \n",
    "    #sorted_ideal_list=sorted(ideal_list, reverse=True)\n",
    "    #get the position that the recommenations have been ranked based on the function used          \n",
    "    \n",
    "    function_ranks=[] #ranks based on the function used. Each function produces a list of recs, get where those recs were ranked based on relevance\n",
    "    for n in recs:    \n",
    "        function_ranks.append([s for s in own['Relevance_score'][own['answer']==n]]) #Relevance scores of each recommended answer\n",
    "    function_ranks=[item for sublist in function_ranks for item in sublist] #stores the relevance scores of the recommendations produced\n",
    "    \n",
    "    ranks=[i+1 for i in range(0, len(ideal_list))] #this is for the ranks based on the number of recommendations on the list\n",
    "    rank_logs=[round(math.log2(i+1),3) for i in ranks]\n",
    "    dcg= sum([x/y for x,y in zip(function_ranks,rank_logs)])\n",
    "    idcg= sum([x/y for x,y in zip(ideal_list, rank_logs)])\n",
    "    ndcg=(dcg/idcg)  \n",
    "    #print(ideal_list)\n",
    "    #print(function_ranks)\n",
    "    #print(len(own))\n",
    "    return ndcg\n",
    "    #return idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849094162816453"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_scores('592')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Candidates(q_id=''):  \n",
    "   \n",
    "    query_id=int(q_id)   \n",
    "    \n",
    "    own=test_data[test_data['query_id']==query_id]\n",
    "    own=own[['query_id','queries','query_question_sim','answer','query_answer_sim','Read2vec_answer','flesch_answer','read2vec_dist','Relevance_score']]\n",
    "    own_tx=own[['query_answer_sim','query_question_sim','read2vec_dist']]    \n",
    "    own_res=lm11.predict(own_tx) #predict the relevance scores for the second model\n",
    "    own['pred']=own_res #put the scores in the dataframe  \n",
    "    own.pred=[int(round(d)) for d in own.pred]\n",
    "\n",
    "\n",
    "    ideal= own.sort_values('Relevance_score', ascending=False) #sorts the dataframe using the satisfaction\n",
    "    ideal=ideal['answer'][:1] #the one with the lowest sat_score is the most relevant, select the first answer\n",
    "    ideal=' '.join(str(s) for s in ideal) #convert answer to string\n",
    "    own_rank= own.sort_values('pred', ascending=False) #firstly rank the selected dataframe by the similarity\n",
    "    \n",
    "    Recs=[s for s in own_rank.answer] #The recommendations are the answers based on the rank\n",
    "    \n",
    "    position= Recs.index(ideal)+1 #check where the relevant answer was ranked among the list of recommendations\n",
    "    #own_rank['MRR']=1/position\n",
    "    #print(position)\n",
    "    return Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cc of water = 1 gram\\t\\t2 liters = 2000 cc = 2000 grams = 2 Kg',\n",
       " 'Firstly, calculate the capacity of the tank in cubic cm.\\t\\t25 x 10 x 8 = 2,000 cubic cm\\t\\tThen convert cubic cm (or \"cc\") to liters: 1,000 cc = 1 litre\\t\\tTherefore the tank holds 2 liters of water.\\t\\t',\n",
       " 'It means the amount of empty space (how much liquid it would hold) in a motorcycle engine when the piston is at the bottom of the stroke.  For instance a chevy 350 Cubic  Inch motor holds 350 cubic inches of liquid.  To compare - a 1600cc holds approx. 95 Cubic Inches of liquid.',\n",
       " 'Only Mazda offered rotary engines, Toyota did not. Mazda still has the RX-8 with a rotary engine.']"
      ]
     },
     "execution_count": 1356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Candidates(593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nd_test=pd.DataFrame(columns=(\"q_id\",\"Combination\",\"Random\",\"Similarity\",\"Flesch_Answer\",\"Read2Vec_distance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nd_test2=pd.DataFrame(columns=(\"q_id\",\"Combination\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nd_test2.q_id=new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nd_test2.Combination=[Lentor_scores(x) for x in nd_test2.q_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.669117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.821197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.822047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.780260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q_id  Combination\n",
       "0     1     0.669117\n",
       "1     2     1.000000\n",
       "2     3     0.821197\n",
       "3     4     0.822047\n",
       "4     5     0.780260"
      ]
     },
     "execution_count": 1489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Candidates_ndcg=[nd_test2['Combination'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8285213417016153]"
      ]
     },
     "execution_count": 1491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Candidates_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Average_Ndcg=pd.DataFrame(columns=('Combination','Random','Flesch_Answer','Read2Vec_distance','Similarity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Random</th>\n",
       "      <th>Flesch_Answer</th>\n",
       "      <th>Read2Vec_distance</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868998</td>\n",
       "      <td>0.832152</td>\n",
       "      <td>0.821687</td>\n",
       "      <td>0.829855</td>\n",
       "      <td>0.861569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Combination    Random  Flesch_Answer  Read2Vec_distance  Similarity\n",
       "0     0.868998  0.832152       0.821687           0.829855    0.861569"
      ]
     },
     "execution_count": 1417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_Ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import letor_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70980974139686548"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letor_metrics.ndcg_score([3, 1],[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Lentor_scores(q_id=''):\n",
    "    que_id=int(q_id)\n",
    "    recs=similarity_rec(que_id)\n",
    "    own= test_data[test_data['query_id']==que_id]    \n",
    "    ideal= own.sort_values('Relevance_score', ascending=False)\n",
    "    ideal_list=[s for s in ideal.Relevance_score]#ideal rank of the items. this list is sorted\n",
    "    ideal_answers=[s for s in ideal.answer] #these are the list of answers when the dataframe is sorted by relevance\n",
    "    #unsorted_list =[s for s in own.Relevance_score] #where it initially ranked the items \n",
    "    #sorted_ideal_list=sorted(ideal_list, reverse=True)\n",
    "    #get the position that the recommenations have been ranked based on the function used          \n",
    "    \n",
    "    function_ranks=[] #ranks based on the function used. Each function produces a list of recs, get where those recs were ranked based on relevance\n",
    "    for n in recs:    \n",
    "        function_ranks.append([s for s in own['Relevance_score'][own['answer']==n]]) #Relevance scores of each recommended answer\n",
    "    function_ranks=[item for sublist in function_ranks for item in sublist][:len(ideal_list)] #stores the relevance scores of the recommendations produced\n",
    "   \n",
    "    #print(function_ranks)\n",
    "    #print(ideal_list)\n",
    "    ndcg= letor_metrics.ndcg_score(ideal_list,function_ranks)\n",
    "    \n",
    "    return ndcg   #return idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85860399650272057"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lentor_scores(592)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "\n",
    "#cnt= Counter(all_ids)\n",
    "#new_ids= [k for k,v in cnt.items() if v>1] #saves query ids that have more than one answer to the question\n",
    "thir_ans_ids= [k for k,v in cnt.items() if v==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 210, 292, 494, 593]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_ans_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_data= test_data[test_data.query_id.isin(two_ans_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_sents=[tokenizer.tokenize(str(s)) for s in data.answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sent=[item for sublist in all_sents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9210"
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sen_len=[len(s) for s in all_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt=[s for s in data.answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sen_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxes=list(set([s for s in sen_len if s>20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_s=[s for s in all_sents if len(s)==161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_s=[item for sublist in long_s for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>queries</th>\n",
       "      <th>question_subject</th>\n",
       "      <th>question_content</th>\n",
       "      <th>answer</th>\n",
       "      <th>query_ans_sat</th>\n",
       "      <th>flesch_query</th>\n",
       "      <th>flesch_answer</th>\n",
       "      <th>Read2vec_query</th>\n",
       "      <th>Read2vec_answer</th>\n",
       "      <th>flesch_dist</th>\n",
       "      <th>read2vec_dist</th>\n",
       "      <th>Relevance_score</th>\n",
       "      <th>query_answer_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>602</td>\n",
       "      <td>Which of the following best describes the diff...</td>\n",
       "      <td>Dose anyone one know anything about The Role o...</td>\n",
       "      <td>Which of the following best describes the diff...</td>\n",
       "      <td>Nuclear families are smaller.\\t\\tI think the a...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>46.78</td>\n",
       "      <td>64.10</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>17.32</td>\n",
       "      <td>0.974907</td>\n",
       "      <td>3</td>\n",
       "      <td>0.338033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>602</td>\n",
       "      <td>Which of the following best describes the diff...</td>\n",
       "      <td>Which of the following best describes the diff...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>I don't see the choices. Nuclear families died...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>46.78</td>\n",
       "      <td>61.97</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.246764</td>\n",
       "      <td>15.19</td>\n",
       "      <td>0.246336</td>\n",
       "      <td>3</td>\n",
       "      <td>0.267321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>105</td>\n",
       "      <td>action reggae song</td>\n",
       "      <td>Old Reggae song, chorus \"i need some action, t...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>Artist - Banton Buju\\tSong - Action</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>76.89</td>\n",
       "      <td>66.40</td>\n",
       "      <td>0.960182</td>\n",
       "      <td>0.959425</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>3</td>\n",
       "      <td>0.163056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>105</td>\n",
       "      <td>action reggae song</td>\n",
       "      <td>WHO SINGS THAT 90'S REGGAE SONG \"ACTION\"?</td>\n",
       "      <td>It's like... Action, by a girl, and then a guy...</td>\n",
       "      <td>Buju Banton</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>76.89</td>\n",
       "      <td>52.53</td>\n",
       "      <td>0.960182</td>\n",
       "      <td>0.628398</td>\n",
       "      <td>24.36</td>\n",
       "      <td>0.331784</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>555</td>\n",
       "      <td>add limewire songs to itunes automatically</td>\n",
       "      <td>How do I transfer music from LimeWire to ITune...</td>\n",
       "      <td>\\t</td>\n",
       "      <td>on your Limewire \\tgo to preferences \\tThe opt...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.74</td>\n",
       "      <td>0.917372</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>55.74</td>\n",
       "      <td>0.081758</td>\n",
       "      <td>3</td>\n",
       "      <td>0.363077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                            queries  \\\n",
       "70       602  Which of the following best describes the diff...   \n",
       "71       602  Which of the following best describes the diff...   \n",
       "75       105                                 action reggae song   \n",
       "76       105                                 action reggae song   \n",
       "77       555         add limewire songs to itunes automatically   \n",
       "\n",
       "                                     question_subject  \\\n",
       "70  Dose anyone one know anything about The Role o...   \n",
       "71  Which of the following best describes the diff...   \n",
       "75  Old Reggae song, chorus \"i need some action, t...   \n",
       "76          WHO SINGS THAT 90'S REGGAE SONG \"ACTION\"?   \n",
       "77  How do I transfer music from LimeWire to ITune...   \n",
       "\n",
       "                                     question_content  \\\n",
       "70  Which of the following best describes the diff...   \n",
       "71                                                 \\t   \n",
       "75                                                 \\t   \n",
       "76  It's like... Action, by a girl, and then a guy...   \n",
       "77                                                 \\t   \n",
       "\n",
       "                                               answer  query_ans_sat  \\\n",
       "70  Nuclear families are smaller.\\t\\tI think the a...       1.333333   \n",
       "71  I don't see the choices. Nuclear families died...       1.428571   \n",
       "75                Artist - Banton Buju\\tSong - Action       1.416667   \n",
       "76                                        Buju Banton       1.500000   \n",
       "77  on your Limewire \\tgo to preferences \\tThe opt...       1.428571   \n",
       "\n",
       "    flesch_query  flesch_answer  Read2vec_query  Read2vec_answer  flesch_dist  \\\n",
       "70         46.78          64.10        0.000428         0.975334        17.32   \n",
       "71         46.78          61.97        0.000428         0.246764        15.19   \n",
       "75         76.89          66.40        0.960182         0.959425        10.49   \n",
       "76         76.89          52.53        0.960182         0.628398        24.36   \n",
       "77          0.00          55.74        0.917372         0.999130        55.74   \n",
       "\n",
       "    read2vec_dist  Relevance_score  query_answer_sim  \n",
       "70       0.974907                3          0.338033  \n",
       "71       0.246336                3          0.267321  \n",
       "75       0.000757                3          0.163056  \n",
       "76       0.331784                2          0.000000  \n",
       "77       0.081758                3          0.363077  "
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[60:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Which of the following best describes the difference between an extended family and a nuclear family'\\n 'Which of the following best describes the difference between an extended family and a nuclear family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'245 querie(s)': '1 answer(s)'},\n",
       " {'61 querie(s)': '2 answer(s)'},\n",
       " {'13 querie(s)': '3 answer(s)'},\n",
       " {'5 querie(s)': '4 answer(s)'},\n",
       " {'4 querie(s)': '5 answer(s)'},\n",
       " {'7 querie(s)': '6 answer(s)'},\n",
       " {'10 querie(s)': '7 answer(s)'},\n",
       " {'10 querie(s)': '8 answer(s)'},\n",
       " {'18 querie(s)': '9 answer(s)'},\n",
       " {'16 querie(s)': '10 answer(s)'},\n",
       " {'17 querie(s)': '11 answer(s)'},\n",
       " {'11 querie(s)': '12 answer(s)'},\n",
       " {'11 querie(s)': '13 answer(s)'},\n",
       " {'7 querie(s)': '14 answer(s)'},\n",
       " {'1 querie(s)': '16 answer(s)'},\n",
       " {'1 querie(s)': '17 answer(s)'},\n",
       " {'1 querie(s)': '18 answer(s)'}]"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
